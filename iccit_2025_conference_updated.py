# -*- coding: utf-8 -*-
"""ICCIT 2025_Conference_updated.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12tFWf9DGdY-bhSNffWpRqBa5vFI6dfIM
"""

import pandas as pd
import matplotlib.pyplot as plt

# Load your dataset
df = pd.read_csv("BanEmoHate.csv")

# Group by HateSpeech and Emotion
grouped = df.groupby(["Hate Comments", "Emotion"]).size().unstack(fill_value=0)

# Plot grouped bar chart
ax = grouped.plot(kind="bar", figsize=(8,6))
plt.title("Emotion Distribution within Hate Speech Classes")
plt.xlabel("HateSpeech")
plt.ylabel("Count")
plt.xticks(rotation=0)
plt.legend(title="Emotion")

# Annotate counts + percentages on bars
for container in ax.containers:
    for bar in container:
        height = bar.get_height()
        if height > 0:
            total = grouped.loc[bar.get_x() + bar.get_width()/2 in bar.get_x(), :].sum() # incorrect method

!pip install --upgrade transformers
import importlib
importlib.reload(__import__('transformers'))

# 1Ô∏è‚É£ Disable W&B
import os
os.environ["WANDB_DISABLED"] = "true"

# 2Ô∏è‚É£ Install required packages
!pip install -q transformers datasets scikit-learn torch accelerate openpyxl
!pip install --upgrade transformers

!pip install transformers datasets torch

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from transformers import AutoTokenizer, AutoModel

import pandas as pd
from torch.utils.data import Dataset, DataLoader
from transformers import XLMRobertaTokenizer
from sklearn.model_selection import train_test_split

# 4Ô∏è‚É£ Load CSV
df = pd.read_csv("/content/BanEmoHate.csv")
df.columns = df.columns.str.strip()

import re
# -------------------------------
# 2. Drop missing & duplicates
# -------------------------------
df = df.dropna(subset=["Comments", "HateSpeech", "Emotion"])
df = df.drop_duplicates()
print("After drop:", df.shape)

# -------------------------------
# 3. Clean Bangla text
# -------------------------------
def clean_bangla_text(Comments):
    text = str(Comments)

    # Remove URLs
    text = re.sub(r"http\S+|www\S+", " ", text)

    # Remove English letters & numbers
    text = re.sub(r"[a-zA-Z0-9]", " ", text)

    # Remove punctuation & symbols (keep only Bangla unicode range)
    text = re.sub(r"[^\u0980-\u09FF\s]", " ", text)

    # Normalize multiple spaces
    text = re.sub(r"\s+", " ", text).strip()

    return text

df["text"] = df["Comments"].apply(clean_bangla_text)

# -------------------------------
# 4. Map labels
# -------------------------------
# Example (change if your dataset already has numeric labels):
emotion_map = {"sad": 0, "angry": 1, "happy": 2}   # happy, sad, angry
hate_map = {"hate": 1, "nonhate": 0}                 # hate=1, not-hate=0

df["emotion"] = df["Emotion"].map(emotion_map).astype(int)
df["hate"] = df["HateSpeech"].map(hate_map).astype(int)

# -------------------------------
# 5. Train/Validation Split
# -------------------------------
train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)

print("Train size:", train_df.shape)
print("Validation size:", val_df.shape)
print(train_df.head())

MODEL_NAME = "xlm-roberta-base"   # you can try "xlm-roberta-large" or "sagorsarker/bangla-bert-base"
MAX_LEN = 128
BATCH_SIZE = 16
LR = 1e-5
EPOCHS = 20
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"



tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

class TextDataset(Dataset):
    def __init__(self, texts, emotion_labels, hate_labels, tokenizer, max_len=MAX_LEN):
        self.texts = texts
        self.emotion_labels = emotion_labels
        self.hate_labels = hate_labels
        self.tokenizer = tokenizer
        self.max_len = max_len

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            self.texts[idx],
            padding="max_length",
            truncation=True,
            max_length=self.max_len,
            return_tensors="pt"
        )
        return {
            "input_ids": encoding["input_ids"].squeeze(),
            "attention_mask": encoding["attention_mask"].squeeze(),
            "emotion": torch.tensor(self.emotion_labels[idx], dtype=torch.long),
            "hate": torch.tensor(self.hate_labels[idx], dtype=torch.long)
        }

train_dataset = TextDataset(train_df["text"].tolist(),
                            train_df["emotion"].tolist(),
                            train_df["hate"].tolist(),
                            tokenizer)

val_dataset = TextDataset(val_df["text"].tolist(),
                          val_df["emotion"].tolist(),
                          val_df["hate"].tolist(),
                          tokenizer)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)

# =========================================================
# 9. Multi-task Model
# =========================================================
class MultiTaskModel(nn.Module):
    def __init__(self, model_name=MODEL_NAME, num_emotions=3, num_hates=2, hidden_dim=256, dropout=0.3):
        super(MultiTaskModel, self).__init__()
        self.encoder = AutoModel.from_pretrained(model_name)
        encoder_hidden = self.encoder.config.hidden_size

        # Emotion classifier head (MLP)
        self.emotion_head = nn.Sequential(
            nn.Linear(encoder_hidden, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, num_emotions)
        )

        # Hate classifier head (MLP)
        self.hate_head = nn.Sequential(
            nn.Linear(encoder_hidden, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, num_hates)
        )

    def forward(self, input_ids, attention_mask):
        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)
        cls_token = outputs.last_hidden_state[:, 0, :]  # [CLS] representation

        emotion_logits = self.emotion_head(cls_token)
        hate_logits = self.hate_head(cls_token)

        return emotion_logits, hate_logits

# Instantiate the model
model = MultiTaskModel().to(DEVICE)

import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, ConfusionMatrixDisplay,
    precision_recall_curve, average_precision_score
)
from itertools import cycle

# =========================================================
# Optimizer & Loss
# =========================================================
optimizer = torch.optim.AdamW(model.parameters(), lr=LR)
criterion_emotion = nn.CrossEntropyLoss()
criterion_hate = nn.CrossEntropyLoss()

# =========================================================
# Training & Evaluation Functions
# =========================================================
def train_model(model, dataloader):
    model.train()
    total_loss = 0

    all_emotion_preds, all_emotion_labels = [], []
    all_hate_preds, all_hate_labels = [], []

    for batch in dataloader:
        input_ids = batch["input_ids"].to(DEVICE)
        attention_mask = batch["attention_mask"].to(DEVICE)
        emotion_labels = batch["emotion"].to(DEVICE)
        hate_labels = batch["hate"].to(DEVICE)

        optimizer.zero_grad()
        emotion_logits, hate_logits = model(input_ids, attention_mask)
        loss_emotion = criterion_emotion(emotion_logits, emotion_labels)
        loss_hate = criterion_hate(hate_logits, hate_labels)
        loss = loss_emotion + loss_hate
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

        # Predictions
        emotion_preds = torch.argmax(emotion_logits, dim=1)
        hate_preds = torch.argmax(hate_logits, dim=1)

        all_emotion_preds.extend(emotion_preds.cpu().numpy())
        all_emotion_labels.extend(emotion_labels.cpu().numpy())
        all_hate_preds.extend(hate_preds.cpu().numpy())
        all_hate_labels.extend(hate_labels.cpu().numpy())

    train_metrics = {
        "emotion_acc": accuracy_score(all_emotion_labels, all_emotion_preds),
        "emotion_f1": f1_score(all_emotion_labels, all_emotion_preds, average="weighted"),
        "hate_acc": accuracy_score(all_hate_labels, all_hate_preds),
        "hate_f1": f1_score(all_hate_labels, all_hate_preds, average="weighted"),
    }
    return total_loss / len(dataloader), train_metrics


def eval_model(model, dataloader):
    model.eval()
    total_loss = 0

    all_emotion_preds, all_emotion_labels = [], []
    all_hate_preds, all_hate_labels = [], []
    all_emotion_probs, all_hate_probs = [], []

    with torch.no_grad():
        for batch in dataloader:
            input_ids = batch["input_ids"].to(DEVICE)
            attention_mask = batch["attention_mask"].to(DEVICE)
            emotion_labels = batch["emotion"].to(DEVICE)
            hate_labels = batch["hate"].to(DEVICE)

            emotion_logits, hate_logits = model(input_ids, attention_mask)
            loss_emotion = criterion_emotion(emotion_logits, emotion_labels)
            loss_hate = criterion_hate(hate_logits, hate_labels)
            total_loss += (loss_emotion + loss_hate).item()

            # Predictions
            emotion_preds = torch.argmax(emotion_logits, dim=1)
            hate_preds = torch.argmax(hate_logits, dim=1)

            all_emotion_preds.extend(emotion_preds.cpu().numpy())
            all_emotion_labels.extend(emotion_labels.cpu().numpy())
            all_hate_preds.extend(hate_preds.cpu().numpy())
            all_hate_labels.extend(hate_labels.cpu().numpy())

            # Probabilities (for PR curve & mAP)
            all_emotion_probs.extend(torch.softmax(emotion_logits, dim=1).cpu().numpy())
            all_hate_probs.extend(torch.softmax(hate_logits, dim=1).cpu().numpy())

    avg_loss = total_loss / len(dataloader)

    metrics = {
        "emotion_acc": accuracy_score(all_emotion_labels, all_emotion_preds),
        "emotion_prec": precision_score(all_emotion_labels, all_emotion_preds, average="weighted"),
        "emotion_rec": recall_score(all_emotion_labels, all_emotion_preds, average="weighted"),
        "emotion_f1": f1_score(all_emotion_labels, all_emotion_preds, average="weighted"),
        "hate_acc": accuracy_score(all_hate_labels, all_hate_preds),
        "hate_prec": precision_score(all_hate_labels, all_hate_preds, average="weighted"),
        "hate_rec": recall_score(all_hate_labels, all_hate_preds, average="weighted"),
        "hate_f1": f1_score(all_hate_labels, all_hate_preds, average="weighted"),
        "emotion_cm": confusion_matrix(all_emotion_labels, all_emotion_preds),
        "hate_cm": confusion_matrix(all_hate_labels, all_hate_preds),
        "emotion_labels": np.array(all_emotion_labels),
        "emotion_preds": np.array(all_emotion_preds),
        "hate_labels": np.array(all_hate_labels),
        "hate_preds": np.array(all_hate_preds),
        "emotion_probs": np.array(all_emotion_probs),
        "hate_probs": np.array(all_hate_probs),
    }
    return avg_loss, metrics

# =========================================================
# Training Loop
# =========================================================
best_emotion_acc, best_emotion_f1 = 0, 0
best_hate_acc, best_hate_f1 = 0, 0
best_metrics = None

for epoch in range(EPOCHS):
    train_loss, train_metrics = train_model(model, train_loader)
    val_loss, val_metrics = eval_model(model, val_loader)

    # Track best metrics
    if val_metrics["emotion_acc"] > best_emotion_acc:
        best_emotion_acc = val_metrics["emotion_acc"]
    if val_metrics["emotion_f1"] > best_emotion_f1:
        best_emotion_f1 = val_metrics["emotion_f1"]
    if val_metrics["hate_acc"] > best_hate_acc:
        best_hate_acc = val_metrics["hate_acc"]
    if val_metrics["hate_f1"] > best_hate_f1:
        best_hate_f1 = val_metrics["hate_f1"]
        best_metrics = val_metrics  # keep best epoch outputs

    print(f"Epoch {epoch+1}/{EPOCHS}")
    print(f" Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}")
    print(f" Emotion Acc: {val_metrics['emotion_acc']:.4f} | F1: {val_metrics['emotion_f1']:.4f}")
    print(f" Hate Acc: {val_metrics['hate_acc']:.4f} | F1: {val_metrics['hate_f1']:.4f}")

print("\n==== BEST METRICS ====")
print(f"Emotion Acc: {best_emotion_acc:.4f}, F1: {best_emotion_f1:.4f}")
print(f"Hate Acc: {best_hate_acc:.4f}, F1: {best_hate_f1:.4f}")

# =========================================================
# Confusion Matrices (Best Epoch)
# =========================================================
fig, axes = plt.subplots(1, 2, figsize=(12,5))
ConfusionMatrixDisplay(best_metrics["emotion_cm"]).plot(ax=axes[0], cmap="Blues", colorbar=False)
axes[0].set_title("Emotion Confusion Matrix")

ConfusionMatrixDisplay(best_metrics["hate_cm"]).plot(ax=axes[1], cmap="Greens", colorbar=False)
axes[1].set_title("Hate Confusion Matrix")
plt.show()

# =========================================================
# Mean Average Precision (mAP) and Precision‚ÄìRecall Curves
# =========================================================
# Emotion (multi-class)
y_true_emotion = best_metrics["emotion_labels"]
y_prob_emotion = best_metrics["emotion_probs"]
n_classes = y_prob_emotion.shape[1]

# One-hot encode
y_true_onehot = np.zeros((len(y_true_emotion), n_classes))
y_true_onehot[np.arange(len(y_true_emotion)), y_true_emotion] = 1

ap_emotion = []
plt.figure(figsize=(8,6))
colors = cycle(["navy", "turquoise", "darkorange", "cornflowerblue", "teal"])
for i, color in zip(range(n_classes), colors):
    precision, recall, _ = precision_recall_curve(y_true_onehot[:, i], y_prob_emotion[:, i])
    ap = average_precision_score(y_true_onehot[:, i], y_prob_emotion[:, i])
    ap_emotion.append(ap)
    plt.plot(recall, precision, color=color, lw=2,
             label=f"Class {i} (AP={ap:.2f})")

plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Emotion Precision-Recall Curves")
plt.legend()
plt.show()

map_emotion = np.mean(ap_emotion)
print(f"Emotion mAP: {map_emotion:.4f}")

# Ground truth and predicted probabilities
y_true_hate = best_metrics["hate_labels"]               # [0,1,...]
y_prob_hate = best_metrics["hate_probs"][:,1]           # Prob for "Hate"
y_prob_nonhate = best_metrics["hate_probs"][:,0]        # Prob for "Non-Hate"

# Hate (positive class = 1)
precision_hate, recall_hate, _ = precision_recall_curve(y_true_hate, y_prob_hate, pos_label=1)
ap_hate = average_precision_score(y_true_hate, y_prob_hate, pos_label=1)

# Non-Hate (positive class = 0)
precision_non, recall_non, _ = precision_recall_curve(y_true_hate, y_prob_nonhate, pos_label=0)
ap_non = average_precision_score(y_true_hate, y_prob_nonhate, pos_label=0)

# Plot PR Curves
plt.figure(figsize=(7,6))
plt.plot(recall_hate, precision_hate, lw=2, color="darkred", label=f"Hate (AP={ap_hate:.2f})")
plt.plot(recall_non, precision_non, lw=2, color="darkblue", label=f"Non-Hate (AP={ap_non:.2f})")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Class-wise Precision-Recall Curve (Hate vs Non-Hate)")
plt.legend()
plt.grid()
plt.show()

print(f"Hate AP: {ap_hate:.4f}")
print(f"Non-Hate AP: {ap_non:.4f}")
print(f"Hate AP: {ap_hate:.4f}")

import torch
from transformers import AutoTokenizer

# Load tokenizer (XLM-RoBERTa)
tokenizer = AutoTokenizer.from_pretrained("xlm-roberta-base")

# Example sentence
test_sentence = "‡¶ì‡¶∞ ‡¶™‡ßÅ‡¶∞‡¶æ ‡¶ó‡ßÅ‡¶∑‡ßç‡¶ü‡¶ø ‡¶∂‡ßç‡¶¨‡¶∂‡ßÅ‡¶∞‡ßá‡¶∞ ‡¶ó‡ßÅ‡¶∑‡ßç‡¶ü‡¶ø ‡¶¨‡¶æ‡¶™‡ßá‡¶∞ ‡¶ó‡ßÅ‡¶∑‡ßç‡¶ü‡¶ø ‡¶∏‡¶¨‡¶æ‡¶∞ ‡¶∏‡¶ï‡¶≤ ‡¶∏‡¶Æ‡ßç‡¶™‡¶§‡ßç‡¶§‡¶ø ‡¶¨‡¶æ‡¶ú‡ßá‡¶Ø‡¶º‡¶æ‡¶™‡ßç‡¶§ ‡¶ï‡¶∞‡¶æ ‡¶π‡ßã‡¶ï ‡¶∏‡ßç‡¶•‡¶æ‡¶¨‡¶∞ ‡¶Ö‡¶∏‡ßç‡¶•‡¶æ‡¶¨‡¶∞ ‡¶∏‡¶¨‡•§"

# Tokenize
inputs = tokenizer(
    test_sentence,
    return_tensors="pt",
    padding=True,
    truncation=True,
    max_length=128
)

# Move to device
inputs = {k: v.to(DEVICE) for k, v in inputs.items()}

# Model inference
model.eval()
with torch.no_grad():
    emotion_logits, hate_logits = model(inputs["input_ids"], inputs["attention_mask"])

# Predictions
emotion_pred = torch.argmax(emotion_logits, dim=1).item()
hate_pred = torch.argmax(hate_logits, dim=1).item()

# Map labels (adjust according to your dataset!)
emotion_map = {0: "Happy", 1: "Sad", 2: "Angry"}
hate_map = {0: "Non-Hate", 1: "Hate"}

print("Input Sentence:", test_sentence)
print("Predicted Emotion:", emotion_map[emotion_pred])
print("Predicted Hate Speech:", hate_map[hate_pred])

import torch
from transformers import AutoTokenizer

# Load tokenizer (XLM-RoBERTa)
tokenizer = AutoTokenizer.from_pretrained("xlm-roberta-base")

# Example sentence
test_sentence = "‡¶Ö‡¶®‡¶∂‡¶® ‡¶™‡ßç‡¶∞‡¶•‡¶æ ‡¶Ø‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶õ‡ßá ‡¶§‡¶æ‡¶ï‡ßá ‡¶®‡ßã‡¶¨‡ßá‡¶≤ ‡¶¶‡ßá‡¶ì‡ßü‡¶æ ‡¶π‡ßã‡¶ï"

# Tokenize
inputs = tokenizer(
    test_sentence,
    return_tensors="pt",
    padding=True,
    truncation=True,
    max_length=128
)

# Move to device
inputs = {k: v.to(DEVICE) for k, v in inputs.items()}

# Model inference
model.eval()
with torch.no_grad():
    emotion_logits, hate_logits = model(inputs["input_ids"], inputs["attention_mask"])

# Predictions
emotion_pred = torch.argmax(emotion_logits, dim=1).item()
hate_pred = torch.argmax(hate_logits, dim=1).item()

# Map labels (adjust according to your dataset!)
emotion_map = {0: "Happy", 1: "Sad", 2: "Angry"}
hate_map = {0: "Non-Hate", 1: "Hate"}

print("Input Sentence:", test_sentence)
print("Predicted Emotion:", emotion_map[emotion_pred])
print("Predicted Hate Speech:", hate_map[hate_pred])

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay

# =========================================================
# Optimizer & Loss
# =========================================================
optimizer = torch.optim.AdamW(model.parameters(), lr=LR)
criterion_emotion = nn.CrossEntropyLoss()
criterion_hate = nn.CrossEntropyLoss()

# =========================================================
# Training & Evaluation Functions
# =========================================================
def train_model(model, dataloader):
    model.train()
    total_loss = 0

    # Initialize lists to store predictions and labels for metrics
    all_emotion_preds, all_emotion_labels = [], []
    all_hate_preds, all_hate_labels = [], []

    for batch in dataloader:
        input_ids = batch["input_ids"].to(DEVICE)
        attention_mask = batch["attention_mask"].to(DEVICE)
        emotion_labels = batch["emotion"].to(DEVICE)
        hate_labels = batch["hate"].to(DEVICE)

        optimizer.zero_grad()
        emotion_logits, hate_logits = model(input_ids, attention_mask)
        loss_emotion = criterion_emotion(emotion_logits, emotion_labels)
        loss_hate = criterion_hate(hate_logits, hate_labels)
        loss = loss_emotion + loss_hate
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

        # Store predictions and labels for metrics
        emotion_preds = torch.argmax(emotion_logits, dim=1)
        hate_preds = torch.argmax(hate_logits, dim=1)

        all_emotion_preds.extend(emotion_preds.cpu().numpy())
        all_emotion_labels.extend(emotion_labels.cpu().numpy())
        all_hate_preds.extend(hate_preds.cpu().numpy())
        all_hate_labels.extend(hate_labels.cpu().numpy())


    # Calculate and return metrics for the training set
    train_metrics = {
        "emotion_acc": accuracy_score(all_emotion_labels, all_emotion_preds),
        "emotion_f1": f1_score(all_emotion_labels, all_emotion_preds, average="weighted"),
        "hate_acc": accuracy_score(all_hate_labels, all_hate_preds),
        "hate_f1": f1_score(all_hate_labels, all_hate_preds, average="weighted"),
    }
    return total_loss / len(dataloader), train_metrics


def eval_model(model, dataloader):
    model.eval()
    total_loss = 0

    all_emotion_preds, all_emotion_labels = [], []
    all_hate_preds, all_hate_labels = [], []

    with torch.no_grad():
        for batch in dataloader:
            input_ids = batch["input_ids"].to(DEVICE)
            attention_mask = batch["attention_mask"].to(DEVICE)
            emotion_labels = batch["emotion"].to(DEVICE)
            hate_labels = batch["hate"].to(DEVICE)

            emotion_logits, hate_logits = model(input_ids, attention_mask)
            loss_emotion = criterion_emotion(emotion_logits, emotion_labels)
            loss_hate = criterion_hate(hate_logits, hate_labels)
            total_loss += (loss_emotion + loss_hate).item()

            # Predictions
            emotion_preds = torch.argmax(emotion_logits, dim=1)
            hate_preds = torch.argmax(hate_logits, dim=1)

            all_emotion_preds.extend(emotion_preds.cpu().numpy())
            all_emotion_labels.extend(emotion_labels.cpu().numpy())
            all_hate_preds.extend(hate_preds.cpu().numpy())
            all_hate_labels.extend(hate_labels.cpu().numpy())

    avg_loss = total_loss / len(dataloader)

    # Metrics
    metrics = {
        "emotion_acc": accuracy_score(all_emotion_labels, all_emotion_preds),
        "emotion_prec": precision_score(all_emotion_labels, all_emotion_preds, average="weighted"),
        "emotion_rec": recall_score(all_emotion_labels, all_emotion_preds, average="weighted"),
        "emotion_f1": f1_score(all_emotion_labels, all_emotion_preds, average="weighted"),
        "hate_acc": accuracy_score(all_hate_labels, all_hate_preds),
        "hate_prec": precision_score(all_hate_labels, all_hate_preds, average="weighted"),
        "hate_rec": recall_score(all_hate_labels, all_hate_preds, average="weighted"),
        "hate_f1": f1_score(all_hate_labels, all_hate_preds, average="weighted"),
        "emotion_cm": confusion_matrix(all_emotion_labels, all_emotion_preds),
        "hate_cm": confusion_matrix(all_hate_labels, all_hate_preds),
        "emotion_labels": all_emotion_labels, # Return labels and predictions for confusion matrix plotting
        "emotion_preds": all_emotion_preds,
        "hate_labels": all_hate_labels,
        "hate_preds": all_hate_preds,
    }
    return avg_loss, metrics

# =========================================================
# Training Loop
# =========================================================
train_losses, val_losses = [], []
train_emotion_accs, val_emotion_accs = [], []
train_hate_accs, val_hate_accs = [], []
train_emotion_f1s, val_emotion_f1s = [], []
train_hate_f1s, val_hate_f1s = [], []


for epoch in range(EPOCHS):
    train_loss, train_metrics = train_model(model, train_loader)
    val_loss, val_metrics = eval_model(model, val_loader)

    train_losses.append(train_loss)
    val_losses.append(val_loss)
    train_emotion_accs.append(train_metrics["emotion_acc"])
    val_emotion_accs.append(val_metrics["emotion_acc"])
    train_hate_accs.append(train_metrics["hate_acc"])
    val_hate_accs.append(val_metrics["hate_acc"])
    train_emotion_f1s.append(train_metrics["emotion_f1"])
    val_emotion_f1s.append(val_metrics["emotion_f1"])
    train_hate_f1s.append(train_metrics["hate_f1"])
    val_hate_f1s.append(val_metrics["hate_f1"])


    print(f"Epoch {epoch+1}/{EPOCHS}")
    print(f" Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}")
    print(f" Emotion Acc: {val_metrics['emotion_acc']:.4f} | F1: {val_metrics['emotion_f1']:.4f}")
    print(f" Hate Acc: {val_metrics['hate_acc']:.4f} | F1: {val_metrics['hate_f1']:.4f}")

# =========================================================
# Plot Loss Curves
# =========================================================
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(train_losses, label="Train Loss")
plt.plot(val_losses, label="Val Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training & Validation Loss")
plt.legend()

# =========================================================
# Plot Accuracy & F1 Curves
# =========================================================
plt.subplot(1,2,2)
plt.plot(val_emotion_accs, label="Emotion Acc")
plt.plot(val_hate_accs, label="Hate Acc")
plt.plot(val_emotion_f1s, label="Emotion F1")
plt.plot(val_hate_f1s, label="Hate F1")
plt.xlabel("Epoch")
plt.ylabel("Score")
plt.title("Validation Accuracy & F1")
plt.legend()
plt.show()

# =========================================================
# Final Confusion Matrices
# =========================================================
fig, axes = plt.subplots(1, 2, figsize=(12,5))
ConfusionMatrixDisplay(val_metrics["emotion_cm"]).plot(ax=axes[0], cmap="Blues", colorbar=False)
axes[0].set_title("Emotion Confusion Matrix")

ConfusionMatrixDisplay(val_metrics["hate_cm"]).plot(ax=axes[1], cmap="Greens", colorbar=False)
axes[1].set_title("Hate Confusion Matrix")
plt.show()



# 10. Training Setup
# =========================================================
optimizer = torch.optim.AdamW(model.parameters(), lr=LR)
criterion_emotion = nn.CrossEntropyLoss()
criterion_hate = nn.CrossEntropyLoss()

# To store curves
train_losses, val_losses = [], []
train_accs_emotion, val_accs_emotion = [], []
train_accs_hate, val_accs_hate = [], []
train_f1s_emotion, val_f1s_emotion = [], []
train_f1s_hate, val_f1s_hate = [], []

# ---------------------------------------------------------
# Training Function
# ---------------------------------------------------------
def train_model(model, dataloader):
    model.train()
    total_loss = 0
    all_emotion_preds, all_emotion_labels = [], []
    all_hate_preds, all_hate_labels = [], []

    for batch in dataloader:
        input_ids = batch["input_ids"].to(DEVICE)
        attention_mask = batch["attention_mask"].to(DEVICE)
        emotion_labels = batch["emotion"].to(DEVICE)
        hate_labels = batch["hate"].to(DEVICE)

        optimizer.zero_grad()
        emotion_logits, hate_logits = model(input_ids, attention_mask)

        # Loss
        loss_emotion = criterion_emotion(emotion_logits, emotion_labels)
        loss_hate = criterion_hate(hate_logits, hate_labels)
        loss = loss_emotion + loss_hate
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

        # Predictions
        emotion_preds = torch.argmax(emotion_logits, dim=1)
        hate_preds = torch.argmax(hate_logits, dim=1)

        all_emotion_preds.extend(emotion_preds.cpu().numpy())
        all_emotion_labels.extend(emotion_labels.cpu().numpy())
        all_hate_preds.extend(hate_preds.cpu().numpy())
        all_hate_labels.extend(hate_labels.cpu().numpy())

    # Metrics
    train_acc_emotion = accuracy_score(all_emotion_labels, all_emotion_preds)
    train_f1_emotion = f1_score(all_emotion_labels, all_emotion_preds, average="weighted")
    train_acc_hate = accuracy_score(all_hate_labels, all_hate_preds)
    train_f1_hate = f1_score(all_hate_labels, all_hate_preds, average="weighted")

    return total_loss / len(dataloader), train_acc_emotion, train_f1_emotion, train_acc_hate, train_f1_hate

# Validation Function
# ---------------------------------------------------------
def eval_model(model, dataloader):
    model.eval()
    total_loss = 0
    all_emotion_preds, all_emotion_labels = [], []
    all_hate_preds, all_hate_labels = [], []

    with torch.no_grad():
        for batch in dataloader:
            input_ids = batch["input_ids"].to(DEVICE)
            attention_mask = batch["attention_mask"].to(DEVICE)
            emotion_labels = batch["emotion"].to(DEVICE)
            hate_labels = batch["hate"].to(DEVICE)

            emotion_logits, hate_logits = model(input_ids, attention_mask)

            loss_emotion = criterion_emotion(emotion_logits, emotion_labels)
            loss_hate = criterion_hate(hate_logits, hate_labels)
            total_loss += (loss_emotion + loss_hate).item()

            emotion_preds = torch.argmax(emotion_logits, dim=1)
            hate_preds = torch.argmax(hate_logits, dim=1)

            all_emotion_preds.extend(emotion_preds.cpu().numpy())
            all_emotion_labels.extend(emotion_labels.cpu().numpy())
            all_hate_preds.extend(hate_preds.cpu().numpy())
            all_hate_labels.extend(hate_labels.cpu().numpy())

    # Metrics
    val_acc_emotion = accuracy_score(all_emotion_labels, all_emotion_preds)
    val_f1_emotion = f1_score(all_emotion_labels, all_emotion_preds, average="weighted")
    val_acc_hate = accuracy_score(all_hate_labels, all_hate_preds)
    val_f1_hate = f1_score(all_hate_labels, all_hate_preds, average="weighted")

    return total_loss / len(dataloader), val_acc_emotion, val_f1_emotion, val_acc_hate, val_f1_hate



# =========================================================
# 11. Run Training
# =========================================================
for epoch in range(EPOCHS):
    train_loss, tr_acc_e, tr_f1_e, tr_acc_h, tr_f1_h = train_model(model, train_loader)
    val_loss, val_acc_e, val_f1_e, val_acc_h, val_f1_h = eval_model(model, val_loader)
    val_loss, emo_labels, emo_preds, hate_labels, hate_preds = eval_model(model, val_loader)

    # Store for curves
    train_losses.append(train_loss)
    val_losses.append(val_loss)
    train_accs_emotion.append(tr_acc_e)
    val_accs_emotion.append(val_acc_e)
    train_accs_hate.append(tr_acc_h)
    val_accs_hate.append(val_acc_h)
    train_f1s_emotion.append(tr_f1_e)
    val_f1s_emotion.append(val_f1_e)
    train_f1s_hate.append(tr_f1_h)
    val_f1s_hate.append(val_f1_h)

    print(f"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}")
    print(f"Emotion -> Train Acc: {tr_acc_e:.4f}, Val Acc: {val_acc_e:.4f}, Train F1: {tr_f1_e:.4f}, Val F1: {val_f1_e:.4f}")
    print(f"Hate    -> Train Acc: {tr_acc_h:.4f}, Val Acc: {val_acc_h:.4f}, Train F1: {tr_f1_h:.4f}, Val F1: {val_f1_h:.4f}")

# =========================================================
# 12. Plot Curves
# =========================================================
epochs = range(1, EPOCHS+1)

# Loss Curves
plt.figure(figsize=(8,5))
plt.plot(epochs, train_losses, label="Train Loss")
plt.plot(epochs, val_losses, label="Val Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Training & Validation Loss")
plt.legend()
plt.show()

# Accuracy Curves
plt.figure(figsize=(8,5))
plt.plot(epochs, train_accs_emotion, label="Train Acc Emotion")
plt.plot(epochs, val_accs_emotion, label="Val Acc Emotion")
plt.plot(epochs, train_accs_hate, label="Train Acc Hate")
plt.plot(epochs, val_accs_hate, label="Val Acc Hate")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("Accuracy Curves")
plt.legend()
plt.show()

# F1 Score Curves
plt.figure(figsize=(8,5))
plt.plot(epochs, train_f1s_emotion, label="Train F1 Emotion")
plt.plot(epochs, val_f1s_emotion, label="Val F1 Emotion")
plt.plot(epochs, train_f1s_hate, label="Train F1 Hate")
plt.plot(epochs, val_f1s_hate, label="Val F1 Hate")
plt.xlabel("Epochs")
plt.ylabel("F1 Score")
plt.title("F1 Score Curves")
plt.legend()
plt.show()

# Plot confusion matrices per epoch
fig, axs = plt.subplots(1, 2, figsize=(12, 5))

cm_emotion = confusion_matrix(emo_labels, emo_preds)
sns.heatmap(cm_emotion, annot=True, fmt="d", cmap="Blues", ax=axs[0])
axs[0].set_title(f"Emotion Confusion Matrix (Epoch {epoch+1})")
axs[0].set_xlabel("Predicted")
axs[0].set_ylabel("Actual")

cm_hate = confusion_matrix(hate_labels, hate_preds)
sns.heatmap(cm_hate, annot=True, fmt="d", cmap="Greens", ax=axs[1])
axs[1].set_title(f"Hate Confusion Matrix (Epoch {epoch+1})")
axs[1].set_xlabel("Predicted")
axs[1].set_ylabel("Actual")
plt.show()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import torch
import torch

# Set device to GPU if available, else CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# Make sure your model is also on the same device
model.to(device)
# Put model in eval mode
model.eval()

all_emotion_preds = []
all_emotion_labels = []

all_hate_preds = []
all_hate_labels = []

with torch.no_grad():
    for batch in val_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)

        emotion_labels = batch['emotion'].to(device)
        hate_labels = batch['hate'].to(device)

        outputs = model(input_ids=input_ids, attention_mask=attention_mask)

        # Assuming your model returns a tuple (emotion_logits, hate_logits)
        emotion_logits, hate_logits = outputs

        # Get predicted class
        emotion_preds = torch.argmax(emotion_logits, dim=1)
        hate_preds = torch.argmax(hate_logits, dim=1)

        # Store all predictions and labels
        all_emotion_preds.extend(emotion_preds.cpu().numpy())
        all_emotion_labels.extend(emotion_labels.cpu().numpy())

        all_hate_preds.extend(hate_preds.cpu().numpy())
        all_hate_labels.extend(hate_labels.cpu().numpy())

# Metrics for Emotion task
print("Emotion Task Metrics:")
print("Accuracy:", accuracy_score(all_emotion_labels, all_emotion_preds))
print("Precision:", precision_score(all_emotion_labels, all_emotion_preds, average='weighted'))
print("Recall:", recall_score(all_emotion_labels, all_emotion_preds, average='weighted'))
print("F1 Score:", f1_score(all_emotion_labels, all_emotion_preds, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(all_emotion_labels, all_emotion_preds))

# Metrics for HateSpeech task
print("\nHateSpeech Task Metrics:")
print("Accuracy:", accuracy_score(all_hate_labels, all_hate_preds))
print("Precision:", precision_score(all_hate_labels, all_hate_preds, average='weighted'))
print("Recall:", recall_score(all_hate_labels, all_hate_preds, average='weighted'))
print("F1 Score:", f1_score(all_hate_labels, all_hate_preds, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(all_hate_labels, all_hate_preds))

# Plot confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.title(f"{task_name} Confusion Matrix")
    plt.show()

# Example: define your classes
emotion_classes = ['happy', 'sad', 'angry']  # modify according to your dataset
hate_classes = ['not_hate', 'hate']          # modify according to your dataset

# Print & plot metrics
print_metrics(all_emotion_labels, all_emotion_preds, "Emotion", emotion_classes)
print_metrics(all_hate_labels, all_hate_preds, "HateSpeech", hate_classes)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

def plot_all_confusion_matrices(y_true_list, y_pred_list, class_names_list, task_names):
    """
    Plots multiple confusion matrices side by side.
    y_true_list, y_pred_list: lists of true/pred labels for each task
    class_names_list: list of class names for each task
    task_names: list of task names
    """
    n_tasks = len(y_true_list)
    fig, axes = plt.subplots(1, n_tasks, figsize=(6*n_tasks, 5))

    if n_tasks == 1:
        axes = [axes]

    for i in range(n_tasks):
        cm = confusion_matrix(y_true_list[i], y_pred_list[i])
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names_list[i], yticklabels=class_names_list[i], ax=axes[i])
        axes[i].set_xlabel('Predicted')
        axes[i].set_ylabel('Actual')
        axes[i].set_title(f'{task_names[i]} Confusion Matrix')

    plt.tight_layout()
    plt.show()

# Example usage
y_true_list = [all_emotion_labels, all_hate_labels]
y_pred_list = [all_emotion_preds, all_hate_preds]
class_names_list = [emotion_classes, hate_classes]
task_names = ['Emotion', 'HateSpeech']

plot_all_confusion_matrices(y_true_list, y_pred_list, class_names_list, task_names)

# =========================================================
# 1. Install dependencies
# =========================================================
!pip install transformers datasets torch pandas scikit-learn

import pandas as pd
import re
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from transformers import AutoTokenizer, AutoModel
from sklearn.model_selection import train_test_split

# =========================================================
# 2. Config
# =========================================================
MODEL_NAME = "xlm-roberta-base"   # you can try "xlm-roberta-large" or "sagorsarker/bangla-bert-base"
MAX_LEN = 128
BATCH_SIZE = 16
LR = 2e-5
EPOCHS = 3
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# =========================================================
# 3. Load CSV
# =========================================================
df = pd.read_csv("/content/your_file.csv")  # üëà change path
print("Original shape:", df.shape)
print(df.head())

# =========================================================
# 4. Drop missing & duplicates
# =========================================================
df = df.dropna(subset=["Comments", "HateSpeech", "Emotion"])
df = df.drop_duplicates()
print("After drop:", df.shape)

# =========================================================
# 5. Clean Bangla text
# =========================================================
def clean_bangla_text(text):
    text = str(text)
    text = re.sub(r"http\S+|www\S+", " ", text)           # remove URLs
    text = re.sub(r"[a-zA-Z0-9]", " ", text)              # remove English letters & numbers
    text = re.sub(r"[^\u0980-\u09FF\s]", " ", text)       # keep only Bangla
    text = re.sub(r"\s+", " ", text).strip()              # normalize spaces
    return text

df["text"] = df["Comments"].apply(clean_bangla_text)

# =========================================================
# 6. Map labels
# =========================================================
# ‚ö†Ô∏è make sure these match your dataset
emotion_map = {"sad": 0, "angry": 1, "happy": 2}
hate_map = {"hate": 1, "nonhate": 0}

df["emotion"] = df["Emotion"].map(emotion_map).astype(int)
df["hate"] = df["HateSpeech"].map(hate_map).astype(int)

# =========================================================
# 7. Train/Validation Split
# =================================

class TextDataset(Dataset):
    def __init__(self, texts, emotion_labels, hatespeech_labels, tokenizer, max_len=MAX_LEN):
        self.texts = texts
        self.emotion_labels = emotion_labels
        self.hatespeech_labels = hatespeech_labels
        self.tokenizer = tokenizer
        self.max_len = max_len

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            self.texts[idx],
            padding="max_length",
            truncation=True,
            max_length=self.max_len,
            return_tensors="pt"
        )
        return {
            "input_ids": encoding["input_ids"].squeeze(),
            "attention_mask": encoding["attention_mask"].squeeze(),
            "emotion": torch.tensor(self.emotion_labels[idx], dtype=torch.long),
            "hate": torch.tensor(self.hatespeech_labels[idx], dtype=torch.long)
        }

# -------------------------------
# 4. Multi-task Model
# -------------------------------
class MultiTaskModel(nn.Module):
    def __init__(self, model_name=MODEL_NAME, num_emotions=3, num_hatespeech=2):
        super(MultiTaskModel, self).__init__()
        self.encoder = AutoModel.from_pretrained(model_name)
        hidden_size = self.encoder.config.hidden_size
        self.emotion_classifier = nn.Linear(hidden_size, num_emotions)
        self.hate_classifier = nn.Linear(hidden_size, num_hatespeech)

    def forward(self, input_ids, attention_mask):
        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)
        cls_token = outputs.last_hidden_state[:, 0, :]   # [CLS]
        emotion_logits = self.emotion_classifier(cls_token)
        hate_logits = self.hate_classifier(cls_token)
        return emotion_logits, hate_logits

# -------------------------------
# 5. Train + Eval
# -------------------------------
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

train_dataset = TextDataset(train_texts, train_emotions, train_hates, tokenizer)
val_dataset = TextDataset(val_texts, val_emotions, val_hates, tokenizer)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)

model = MultiTaskModel().to(DEVICE)
optimizer = torch.optim.AdamW(model.parameters(), lr=LR)
criterion_emotion = nn.CrossEntropyLoss()
criterion_hate = nn.CrossEntropyLoss()

def train_model(model, dataloader):
    model.train()
    total_loss = 0
    for batch in dataloader:
        input_ids = batch["input_ids"].to(DEVICE)
        attention_mask = batch["attention_mask"].to(DEVICE)
        emotion_labels = batch["emotion"].to(DEVICE)
        hate_labels = batch["hate"].to(DEVICE)

        optimizer.zero_grad()
        emotion_logits, hate_logits = model(input_ids, attention_mask)
        loss_emotion = criterion_emotion(emotion_logits, emotion_labels)
        loss_hate = criterion_hate(hate_logits, hate_labels)
        loss = loss_emotion + loss_hate
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(dataloader)

def eval_model(model, dataloader):
    model.eval()
    total_loss = 0
    with torch.no_grad():
        for batch in dataloader:
            input_ids = batch["input_ids"].to(DEVICE)
            attention_mask = batch["attention_mask"].to(DEVICE)
            emotion_labels = batch["emotion"].to(DEVICE)
            hate_labels = batch["hate"].to(DEVICE)

            emotion_logits, hate_logits = model(input_ids, attention_mask)
            loss_emotion = criterion_emotion(emotion_logits, emotion_labels)
            loss_hate = criterion_hate(hate_logits, hate_labels)
            loss = loss_emotion + loss_hate
            total_loss += loss.item()
    return total_loss / len(dataloader)

for epoch in range(EPOCHS):
    train_loss = train_model(model, train_loader)
    val_loss = eval_model(model, val_loader)
    print(f"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}")

import re

# Define mappings
emotion_map = {"happy": 0, "sad": 1, "angry": 2}
hate_map = {"nonhate": 0, "hate": 1}

# Clean comments (normalize whitespace)
df['text'] = df['Comments'].apply(lambda x: re.sub(r'\s+', ' ', str(x)).strip())

# Apply mappings
df['emotion_label'] = df['Emotion'].map(emotion_map)
df['hate_label'] = df['HateSpeech'].map(hate_map)

# Check for unmapped values (to catch extra categories)
unmapped_emotions = df[df['emotion_label'].isna()]['Emotion'].unique()
unmapped_hates = df[df['hate_label'].isna()]['HateSpeech'].unique()

print("Unmapped Emotion:", unmapped_emotions)
print("Unmapped HateSpeech:", unmapped_hates)

import re

# Define mappings
emotion_map = {"happy": 0, "sad": 1, "angry": 2}
hate_map = {"nonhate": 0, "hate": 1}

# Clean comments (normalize whitespace)
df['text'] = df['Comments'].apply(lambda x: re.sub(r'\s+', ' ', str(x)).strip())

# Apply mappings
df['emotion_label'] = df['Emotion'].map(emotion_map)
df['hate_label'] = df['HateSpeech'].map(hate_map)

# Check for unmapped values (to catch extra categories)
unmapped_emotions = df[df['emotion_label'].isna()]['Emotion'].unique()
unmapped_hates = df[df['hate_label'].isna()]['HateSpeech'].unique()

print("Unmapped Emotion:", unmapped_emotions)
print("Unmapped HateSpeech:", unmapped_hates)



MODEL_NAME = "xlm-roberta-base"   # change to "roberta-base" or "xlm-roberta-large"
MAX_LEN = 128
BATCH_SIZE = 16
LR = 2e-5
EPOCHS = 3
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# -------------------------------
# 2. Dataset Class
# -------------------------------
class TextDataset(Dataset):
    def __init__(self, texts, emotion_labels, hatespeech_labels, tokenizer, max_len=MAX_LEN):
        self.texts = texts
        self.emotion_labels = emotion_labels
        self.hatespeech_labels = hatespeech_labels
        self.tokenizer = tokenizer
        self.max_len = max_len

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            self.texts[idx],
            padding="max_length",
            truncation=True,
            max_length=self.max_len,
            return_tensors="pt"
        )
        return {
            "input_ids": encoding["input_ids"].squeeze(),
            "attention_mask": encoding["attention_mask"].squeeze(),
            "emotion": torch.tensor(self.emotion_labels[idx], dtype=torch.long),
            "hate": torch.tensor(self.hatespeech_labels[idx], dtype=torch.long)
        }

# -------------------------------
# 3. Multi-task Model
# -------------------------------
class MultiTaskModel(nn.Module):
    def __init__(self, model_name=MODEL_NAME, num_emotions=3, num_hatespeech=2):
        super(MultiTaskModel, self).__init__()
        self.encoder = AutoModel.from_pretrained(model_name)
        hidden_size = self.encoder.config.hidden_size
        self.emotion_classifier = nn.Linear(hidden_size, num_emotions)
        self.hate_classifier = nn.Linear(hidden_size, num_hatespeech)

    def forward(self, input_ids, attention_mask):
        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)
        cls_token = outputs.last_hidden_state[:, 0, :]   # [CLS] token
        emotion_logits = self.emotion_classifier(cls_token)
        hate_logits = self.hate_classifier(cls_token)
        return emotion_logits, hate_logits

def train_model(model, dataloader, optimizer, criterion_emotion, criterion_hate):
    model.train()
    total_loss = 0
    for batch in dataloader:
        input_ids = batch["input_ids"].to(DEVICE)
        attention_mask = batch["attention_mask"].to(DEVICE)
        emotion_labels = batch["emotion"].to(DEVICE)
        hate_labels = batch["hate"].to(DEVICE)

        optimizer.zero_grad()
        emotion_logits, hate_logits = model(input_ids, attention_mask)
        loss_emotion = criterion_emotion(emotion_logits, emotion_labels)
        loss_hate = criterion_hate(hate_logits, hate_labels)
        loss = loss_emotion + loss_hate
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(dataloader)

# -------------------------------
# 5. Example Run (with dummy data)
# -------------------------------
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)


emotion_labels = [0, 1, 2, 0]   # 0=happy,1=sad,2=angry
hatespeech_labels = [0, 0, 1, 0]  # 0=not-hate,1=hate

dataset = TextDataset(df, emotion_labels, hatespeech_labels, tokenizer)
dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)

model = MultiTaskModel().to(DEVICE)
optimizer = torch.optim.AdamW(model.parameters(), lr=LR)
criterion_emotion = nn.CrossEntropyLoss()
criterion_hate = nn.CrossEntropyLoss()

for epoch in range(EPOCHS):
    loss = train_model(model, dataloader, optimizer, criterion_emotion, criterion_hate)
    print(f"Epoch {epoch+1}/{EPOCHS}, Loss: {loss:.4f}")